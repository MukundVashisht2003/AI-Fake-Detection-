{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":325628,"sourceType":"modelInstanceVersion","modelInstanceId":273759,"modelId":294650}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/images'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"1e607c8e-4f1a-4558-907f-8819005eb2b6","_cell_guid":"52d1f386-80a2-4715-88fb-7360fe643a90","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"import warnings\n\n# Filter out specific warning by category\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)","metadata":{"_uuid":"b4ea0f9c-aeaf-4cea-bdc0-f574d738b0c7","_cell_guid":"d0a84196-48a0-4bc3-9f95-fc90eb77a415","trusted":true,"collapsed":false,"execution":{"execution_failed":"2025-04-07T13:14:06.960Z"},"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import tensorflow as tf\nimport os","metadata":{"_uuid":"10cb09de-c080-4080-8a85-91f55154cae7","_cell_guid":"f82fb3a3-8543-4374-b45a-e921493195f3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Image size and batch size\nimage_size = (380, 380)\nbatch_size = 64","metadata":{"_uuid":"b625a705-0060-4b0d-ae1b-323dad11f1b8","_cell_guid":"ffafc645-cd81-45a9-9bb1-7fc49f973058","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# The main folder\nbase_path = '/kaggle/input/images'\n\n# Create list of file paths and corresponding labels\nfile_paths = []\nlabels = []\n\n# Iterate through 'fake' and 'real' subfolders to collect file paths and labels\nfor label, category in enumerate(['fake', 'real']):\n    category_path = os.path.join(base_path, category)\n    for file_name in os.listdir(category_path):\n        file_path = os.path.join(category_path, file_name)\n        file_paths.append(file_path)\n        labels.append(label)  # Assign label 0 for 'fake' and 1 for 'real'","metadata":{"_uuid":"5fb59856-1045-4228-a38e-73903c88a42c","_cell_guid":"4b3efd39-3443-4cf2-a3d9-f2af5ea93f4f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Check class distribution\nclass_distribution = pd.Series(labels).value_counts()\nprint(\"Class Distribution:\")\nprint(class_distribution)\n\n# Calculate class percentages\ntotal_samples = len(labels)\nclass_percentages = class_distribution / total_samples\nprint(\"\\nClass Percentages:\")\nprint(class_percentages)","metadata":{"_uuid":"5cbff2da-98f3-4e78-8433-0875cccc4df7","_cell_guid":"f77e6a44-273a-42f0-9043-8bf85d92a640","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\n# Check the dimension of the data\ndef get_image_dimensions(file_path):\n    img = cv2.imread(file_path)\n\n    if img is not None:\n        # Get image dimensions (height, width, channels)\n        height, width, channels = img.shape\n        return height, width, channels\n    else:\n        print(f\"Error: Failed to load image at {file_path}\")\n        return None\n\n# Display dimensions of the first 5 images\nnum_images_to_display = 5\n\nif len(file_paths) >= num_images_to_display:\n    print(f\"Displaying dimensions of the first {num_images_to_display} images:\")\n\n    for i in range(num_images_to_display):\n        image_path = file_paths[i]\n        dimensions = get_image_dimensions(image_path)\n\n        if dimensions is not None:\n            height, width, channels = dimensions\n            print(f\"Image {i+1}:\")\n            print(f\"  Height: {height} pixels\")\n            print(f\"  Width: {width} pixels\")\n            print(f\"  Channels (depth): {channels}\")\n        else:\n            print(f\"Image {i+1}: Error loading image dimensions\")\nelse:\n    print(\"No image files found\")","metadata":{"_uuid":"64d6a2c8-0ab0-4a79-a6af-077810fe5385","_cell_guid":"10eda414-87ca-4927-b3ef-c6721c24065b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport random\n\nnum_images_to_display = 5\n\nif len(file_paths) >= num_images_to_display:\n    plt.figure(figsize=(15, 8))\n    random_indices = random.sample(range(len(file_paths)), num_images_to_display)\n\n    for i, idx in enumerate(random_indices):\n        image_path = file_paths[idx]\n        label = labels[idx]\n        img = cv2.imread(image_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for matplotlib\n\n        # Display image with label\n        plt.subplot(1, num_images_to_display, i + 1)\n        plt.imshow(img)\n\n        if label == 0:\n            plt.title(\"Fake\")\n        elif label == 1:\n            plt.title(\"Real\")\n\n        plt.axis('off')\n\n    plt.show()\nelse:\n    print(\"No image files found\")","metadata":{"_uuid":"f6ae36ae-b9f1-403c-819a-4661d9bc79e5","_cell_guid":"1dc0ad06-36da-492e-8599-d601ebcad491","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_augmentation_layers = [\n    tf.keras.layers.RandomRotation(factor=0.15),\n    tf.keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n    tf.keras.layers.RandomFlip('horizontal'),\n    tf.keras.layers.RandomContrast(factor=0.1)\n]","metadata":{"_uuid":"7a9e9653-f77a-4a82-95d3-f16bd686f727","_cell_guid":"fe1294ea-57cf-4b1f-b1fc-9f60861ecccb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\n# Function to preprocess the data with optional data augmentation and manual normalization\ndef preprocess_image(file_path, label, augment=False, image_size=(380, 380)):\n    # Load and decode image\n    img = tf.io.read_file(file_path)\n    img = tf.image.decode_jpeg(img, channels=3)  # Ensure 3 channels (RGB)\n\n    # Apply image augmentation if specified\n    if augment:\n        for layer in img_augmentation_layers:\n            img = layer(img)\n\n\n    # Resize image to the required input size for EfficientNetB4\n    img = tf.image.resize(img, image_size)\n\n\n    # Preprocess image using EfficientNet preprocessing\n    img = preprocess_input(img)\n\n    return img, label","metadata":{"_uuid":"38a60832-9987-40df-9a3b-10fe7ff52883","_cell_guid":"687620cf-e4ba-4f64-95bf-1efd63b1b010","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split data into training, validation, and test sets with stratified sampling\ntrain_file_paths, test_file_paths, train_labels, test_labels = train_test_split(file_paths, labels, test_size=0.2, stratify=labels, random_state=42)\n\ntrain_file_paths, val_file_paths, train_labels, val_labels = train_test_split(train_file_paths, train_labels, test_size=0.25, stratify=train_labels, random_state=42)\n\n# Print the length\nprint(\"Number of training samples:\", len(train_file_paths))\nprint(\"Number of training labels:\", len(train_labels))\nprint(\"Number of validation samples:\", len(val_file_paths))\nprint(\"Number of validation labels:\", len(val_labels))\nprint(\"Number of test samples:\", len(test_file_paths))\nprint(\"Number of test labels:\", len(test_labels))","metadata":{"_uuid":"215a5aae-7713-4aba-a222-63c1442b9374","_cell_guid":"fab0675e-bd6c-4f1f-9e51-ee9e6db5989a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.utils import is_keras_tensor\nimport tensorflow as tf\n\nx = tf.keras.Input(shape=(10,))\nprint(is_keras_tensor(x))  # Should print True","metadata":{"_uuid":"132df279-d5a7-4365-a8b2-b4c073d04903","_cell_guid":"0268d570-11ae-4771-9ca0-f81b862582bf","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create TensorFlow datasets for training, validation, and test\n#rom tensorflow.keras.engine.keras_tensor import KerasTensor\n\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_file_paths, train_labels))\nval_dataset = tf.data.Dataset.from_tensor_slices((val_file_paths, val_labels))\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_file_paths, test_labels))\n\n# Map preprocessing function to the datasets\n# Only perform data augmentation on Train dataset\ntrain_dataset = train_dataset.map(lambda x, y: preprocess_image(x, y, augment=True), num_parallel_calls=tf.data.AUTOTUNE)\nval_dataset = val_dataset.map(lambda x, y: preprocess_image(x, y, augment=False), num_parallel_calls=tf.data.AUTOTUNE)\ntest_dataset = test_dataset.map(lambda x, y: preprocess_image(x, y, augment=False), num_parallel_calls=tf.data.AUTOTUNE)\n\n# Shuffle and batch the training dataset\ntrain_dataset = train_dataset.shuffle(buffer_size=len(train_file_paths)).batch(batch_size)\n\n# Batch the validation dataset. I wont shuffle and perform data augmentation on  test and vad\nval_dataset = val_dataset.batch(batch_size)\n\n# Batch the test dataset\ntest_dataset = test_dataset.batch(batch_size)","metadata":{"_uuid":"34ff648d-1949-473f-bc89-9bbacc0e497c","_cell_guid":"c03c9f62-45f1-4efe-9c13-9e21591c8830","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Function to display preprocessed image\n# def show_preprocessed_images(dataset, num_images=5):\n#     plt.figure(figsize=(15, 10))\n#     for i, (image, label) in enumerate(dataset.take(1)): # only 1 batch\n#         for j in range(num_images):\n#             plt.subplot(1, num_images, j + 1)\n#             plt.imshow(image[j])  # Display j-th image in the batch\n#             plt.title(f\"Label: {label[j].numpy()}\")\n#             plt.axis(\"off\")\n#     plt.show()\n# # Visualize preprocessed images from the train dataset\n# print(\"Visualizing preprocessed images from the train dataset:\")\n# show_preprocessed_images(train_dataset)","metadata":{"_uuid":"5cfde1cc-7688-4a60-8a11-9c61b12092cd","_cell_guid":"ea56ec93-7996-4ed1-8060-8dee092cc7d0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB4\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n\n# Build the base model architecture\nbase_model = EfficientNetB4(\n    include_top=False,\n    weights=None,  # Don't load imagenet weights, we'll load your .h5 weights\n    input_shape=(image_size[0], image_size[1], 3)\n)\n\n# Load weights into the base model\nbase_model.load_weights('/kaggle/input/efficientnetb4/tensorflow2/default/1/efficientnetb4_notop.h5')\n\n# Freeze the base model layers\nbase_model.trainable = False\n\n# Add classification head\nmodel = tf.keras.Sequential([\n    base_model,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.001))\n])\n\n# Compile the model\noptimizer = Adam(learning_rate=0.001)\nmodel.compile(optimizer=optimizer,\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Callbacks\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6)\n\n# Model summary\nmodel.summary()","metadata":{"_uuid":"771bb8f7-b9bf-45d7-af04-511446545774","_cell_guid":"6a2ee901-bc5b-4cfd-bb82-ac34c7f6c2f7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the model with fine-tuning\nepochs = 5\nmodel.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=[reduce_lr])","metadata":{"_uuid":"4f6d8d2e-9205-4937-9687-670ef2dce184","_cell_guid":"8736bec5-1a67-41bc-917b-3175b9c4571c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Unfreeze the last 20 layers of the base model\nfine_tune_at = -20\n\n# Unfreeze the selected layers for fine-tuning\nfor layer in base_model.layers[fine_tune_at:]:\n    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n        layer.trainable = True\n\n# Specify a lower learning rate for the fine-tuned layers\noptimizer = Adam(learning_rate=0.0001)  # Lower learning rate for fine-tuned layers\nmodel.compile(optimizer=optimizer,\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Set up a learning rate reduction scheduler\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n\n# ModelCheckpoint callback to save the best model based on validation loss\ncheckpoint_callback = ModelCheckpoint(\n    filepath='best_model_fc.keras',\n    monitor='val_loss',  # Monitor validation loss\n    save_best_only=True,  # Save only the best model\n    mode='min',  # Save the model with the lowest validation loss\n    verbose=1\n)","metadata":{"_uuid":"8ab45a9e-461b-43bf-8578-2eefbfd15e7e","_cell_guid":"37dd87cf-3446-42e5-af4e-96dbf29f033a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the model with fine-tuning\nepochs = 5   \nmodel.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=[reduce_lr , checkpoint_callback])","metadata":{"_uuid":"916df1a2-b643-4133-b5ff-26dcef09b30f","_cell_guid":"f311890f-82e9-4561-b527-f585bb36bade","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model on the test dataset\ntest_loss, test_accuracy = model.evaluate(test_dataset)\nprint(f\"Test Loss: {test_loss}\")\nprint(f\"Test Accuracy: {test_accuracy}\")","metadata":{"_uuid":"2bfec198-4854-4162-b4c3-8182948dfb11","_cell_guid":"c5d3c9c0-7d8d-421b-8d99-13ba57c1908e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Predictions on the test dataset\npredictions = model.predict(test_dataset)\npredicted_labels = (predictions > 0.5).astype(int)  # Convert probabilities to binary predictions (0 or 1)\n\n# Convert labels from dataset to numpy array for evaluation\ntrue_labels = np.array(test_labels)\n\n# Compute confusion matrix\ncm = confusion_matrix(true_labels, predicted_labels)\n\n# Calculate precision, recall, and F1 score\nprecision = cm[1, 1] / (cm[1, 1] + cm[0, 1])  # TP / (TP + FP)\nrecall = cm[1, 1] / (cm[1, 1] + cm[1, 0])     # TP / (TP + FN)\nf1_score = 2 * (precision * recall) / (precision + recall)\n\nprint(\"Confusion Matrix:\")\nprint(cm)\nprint(\"\\nClassification Report:\")\nprint(classification_report(true_labels, predicted_labels, target_names=['fake', 'real']))\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1_score:.4f}\")","metadata":{"_uuid":"ce7d555b-786f-48f6-9228-a156953138ac","_cell_guid":"df2f3699-3e5e-494a-ac6b-e6e9b90dfa03","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\n\n# Compute confusion matrix\ncm = confusion_matrix(true_labels, predicted_labels)\n\n# Define labels for the matrix\nlabels = ['Fake', 'Real']\n\n# Plot confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"_uuid":"d4701373-2622-410a-a1d1-723e93c6f33b","_cell_guid":"d60ef6ac-ac91-4d77-bf80-1b4c30d067a4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\n\n# Predictions on the test dataset\n\npredicted_probabilities = predictions.ravel()  # Flatten predictions to 1D array\n\n# Convert labels from dataset to numpy array for evaluation\ntrue_labels = np.array(test_labels)\n\n# Compute ROC curve and AUC\nfpr, tpr, thresholds = roc_curve(true_labels, predicted_probabilities)\nroc_auc = auc(fpr, tpr)\n\n# Plot ROC curve\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=1)  # Diagonal line\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curve')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"_uuid":"6c036dcb-5c8d-4070-9c82-5b23871c14c2","_cell_guid":"d8cf685a-5289-43c1-bc59-507224e32346","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate model performance on validation dataset\nval_loss, val_accuracy = model.evaluate(val_dataset)\nprint(f\"Validation Loss: {val_loss}\")\nprint(f\"Validation Accuracy: {val_accuracy}\")","metadata":{"_uuid":"91f9b590-4226-4c0f-9651-4cfab392c7eb","_cell_guid":"3bbb5230-30ba-4a99-830d-825988c80c23","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# image path\nimage_path = \"/kaggle/input/images/real/0000.jpg\"\n\n# Load and preprocess the image using preprocess_image function\ndef load_and_preprocess_image(file_path):\n    # Read the image file\n    img = tf.io.read_file(file_path)\n    # Decode the image to RGB format\n    img = tf.image.decode_jpeg(img, channels=3)\n    # Resize the image to match the input size for EfficientNetB4\n    img = tf.image.resize(img, (380, 380))\n    # Preprocess the image using EfficientNet preprocessing\n    img = preprocess_input(img)\n    return img\n\n# Load and preprocess the image\ninput_image = load_and_preprocess_image(image_path)\n\n# Reshape the image to a batch of 1 (since we're predicting a single image)\ninput_image = np.expand_dims(input_image, axis=0)\n\n# Make prediction\nprediction = model.predict(input_image)\n\n# Display the raw predicted probabilities\nprint(f\"Raw Prediction: {prediction}\")\n\n# Interpret the prediction\nprobability_fake = prediction[0][0]\nprobability_real = 1 - probability_fake\n\n# Display the interpreted probabilities\nprint(f\"Probability for 'fake' class: {probability_fake:.4f}\")\nprint(f\"Probability for 'real' class: {probability_real:.4f}\")\n\npredicted_class = 'fake' if probability_fake > 0.5 else 'real'\nprint(f\"Predicted Class: {predicted_class}\")","metadata":{"_uuid":"b55817e6-e37d-45d4-a535-ea5dfd5559f5","_cell_guid":"b26a9a77-45b6-4786-a554-f5ae54502f28","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nsaved_model_path = \"Saved_Model_2\"\n\n# Save the model to the specified path\n\nmodel.save(saved_model_path)","metadata":{"_uuid":"82fe2296-995c-4842-bcd6-19baf3945a37","_cell_guid":"27442781-7449-400b-9ee5-8113ee3a0bef","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\"/kaggle/working/Saved_Model_2\", 'zip', \"Saved_Model_2\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n\n# os.remove(\"/kaggle/working/Saved_Model_2.zip\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}